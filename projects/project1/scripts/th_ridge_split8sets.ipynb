{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the 8 split datasets based on mass and jet number presence, we try ridge regression to predict outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dupplicate code from the dataset splitting\n",
    "\n",
    "We have dupplicated it so as not to have git conflicts, but it should be the same with project1 - Alon.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove features with error values\n",
    "y_jet = []\n",
    "tx_jet = []\n",
    "y_jet_nm = []\n",
    "tx_jet_nm = []\n",
    "# filtering according to undefinition due to jet number\n",
    "idx_jet_undef = [np.array([0,1,2,3,7,10,11,13,14,15,16,17,18,19,20,21,29]),\n",
    "                np.array([0,1,2,3,7,8,9,10,11,13,14,15,16,17,18,19,20,21,23,24,25,29]),\n",
    "                np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,23,24,25,26,27,28,29]),\n",
    "                np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,23,24,25,26,27,28,29])]\n",
    "\n",
    "# Extra filtering according to definition of mass\n",
    "idx_jet_undef_nm = [np.array([1,2,3,7,10,11,13,14,15,16,17,18,19,20,21,29]),\n",
    "                    np.array([1,2,3,7,8,9,10,11,13,14,15,16,17,18,19,20,21,23,24,25,29]),\n",
    "                    np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,23,24,25,26,27,28,29]),\n",
    "                    np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,23,24,25,26,27,28,29])]\n",
    "\n",
    "for jet in range(4):\n",
    "    idx_jet = (tX[:,22]==jet) & (tX[:,0] != -999)\n",
    "    y_jet.append(y[idx_jet])\n",
    "    tx_jet.append(tX[idx_jet][:,idx_jet_undef[jet]])\n",
    "    # tx_jet.append(standardize(tX[idx_jet]))\n",
    "\n",
    "for jet in range(4): # NB : no mass also has dupplicates from data that has mass, to have more data available for training.\n",
    "    idx_jet = tX[:,22]==jet\n",
    "    y_jet_nm.append(y[idx_jet])\n",
    "    tx_jet_nm.append(tX[idx_jet][:,idx_jet_undef_nm[jet]])\n",
    "    # tx_jet.append(standardize(tX[idx_jet]))\n",
    "\n",
    "for jet in range(4):\n",
    "    print('Jet {:} shape is {:}'.format(jet,tx_jet[jet].shape))\n",
    "    print('Jet no mass {:} shape is {:}'.format(jet,tx_jet_nm[jet].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression implementation for this set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_col_select_split = []\n",
    "y_split = []\n",
    "tx_split = []\n",
    "\n",
    "for jet in range(4):\n",
    "    idx_jet = (tX[:,22]==jet) & (tX[:,0] != -999)\n",
    "    y_split.append(y[idx_jet])\n",
    "    tx_split.append(tX[idx_jet][:,idx_jet_undef[jet]])\n",
    "\n",
    "for jet in range(4): # NB : no mass also has dupplicates from data that has mass, to have more data available for training.\n",
    "    idx_jet = tX[:,22]==jet\n",
    "    y_split.append(y[idx_jet])\n",
    "    tx_split.append(tX[idx_jet][:,idx_jet_undef_nm[jet]])\n",
    "    \n",
    "# print(y_split)\n",
    "# print(tx_split[0][0])\n",
    "for set_i in range(8):\n",
    "    print(f'Set {set_i} shape is {tx_split[set_i].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the datasets, we now have to train a model. We will use ridge regression, with different lambdas to find the best one. We use a high polynomial expansion because optimising for lambda should mean that any high degree will be compensated by the ridge regression when optimised. Therefore we use any high degree that guarantees our model is not limited by it's complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab3_plots import plot_train_test\n",
    "from th_helpers import build_poly, split_data, compute_rmse\n",
    "from th_ridge_regression import ridge_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_lambdas(x, y, degree, ratio, seed, lambdas):#=np.logspace(-5, 0, 15)):\n",
    "    \"\"\"Performs ridge regression with multiple lambdas.\"\"\"\n",
    "    # split the data, and return train and test data: TODO\n",
    "    train_x, train_y, test_x, test_y = split_data(x, y, ratio, seed)\n",
    "\n",
    "    # form train and test data with polynomial basis function: TODO\n",
    "    train_x_aug = build_poly(train_x, degree)\n",
    "    test_x_aug = build_poly(test_x, degree)\n",
    "\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    \n",
    "    min_w_te = []\n",
    "    min_rmse_te = -1\n",
    "    best_lambda = False\n",
    "    best_correctness = -1\n",
    "    \n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "\n",
    "        # ridge regression with a given lambda        \n",
    "        w = ridge_regression(train_y, train_x_aug, lambda_)\n",
    "        \n",
    "        rmse_tr.append(compute_rmse(train_y, train_x_aug, w))\n",
    "        rmse_te.append(compute_rmse(test_y, test_x_aug, w))\n",
    "        \n",
    "        if rmse_te[ind] < min_rmse_te or min_rmse_te == -1:\n",
    "            min_rmse_te = rmse_te[ind]\n",
    "            min_w_te = w\n",
    "            best_lambda = lambda_\n",
    "            \n",
    "        # ***************************************************\n",
    "#         print(\"proportion={p}, degree={d}, lambda={l:.3f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "#                p=ratio, d=degree, l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))\n",
    "    \n",
    "    # Compute correctness of best result \n",
    "    y_out_test = np.dot(test_x_aug, min_w_te)\n",
    "    y_out_test[y_out_test>=0] = 1\n",
    "    y_out_test[y_out_test<0] = -1\n",
    "    best_correctness = 100*(y_out_test == test_y).tolist().count(True)/y_out_test.shape[0]\n",
    "            \n",
    "    # Plot the obtained results\n",
    "    print(f\"Degree={degree}, ratio={np.round(ratio, 3)}, seed={seed}, min test RMSE={np.round(min_rmse_te, 4)}, with correctness ={np.round(best_correctness, 2)}% ({len(y_out_test)} test points) and lambda={np.round(best_lambda, 7)}\")\n",
    "    plot_train_test(rmse_tr, rmse_te, lambdas, degree)\n",
    "    \n",
    "    return min_rmse_te, min_w_te, best_lambda\n",
    "\n",
    "# THEOTEST code\n",
    "# ridge_regression_demo(x=np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).T, \n",
    "#                       y=np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]).T,\n",
    "#                       degree = 3,\n",
    "#                       ratio = 0.7,\n",
    "#                       seed = 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 150\n",
    "degree = 5\n",
    "split_ratio = 0.9\n",
    "lambdas = np.logspace(-5, 5, 1000)\n",
    "\n",
    "for set_i in range(8):\n",
    "    print(f\"\\nAnalysing set={set_i}\")\n",
    "    min_rmse_te, min_w_te, best_lambda = ridge_regression_lambdas(tx_split[set_i], y_split[set_i], degree, split_ratio, seed, lambdas)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now actual ridge regression with output file\n",
    "\n",
    "We need to split the test data the same way, but keeping the ids in order to reconstruct it afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
